{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g_6gP-S8Kurv"
   },
   "outputs": [],
   "source": [
    "input_dir = './datasets/oxford_pets/images/images/'\n",
    "target_dir = './datasets/oxford_pets/annotations/annotations/trimaps/'\n",
    "img_siz = (160,160)\t # 모델에 입력되는 영상 크기\n",
    "n_class = 3\t\t       # 분할 레이블 (1:물체, 2:배경, 3:경계)\n",
    "batch_siz = 32\t\t   # 미니 배치 크기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FZnpdZPgMvy8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "img_paths = sorted([os.path.join(input_dir, f) for f in os.listdir(input_dir) if f.endswith('.jpg')])\n",
    "label_paths = sorted([os.path.join(target_dir, f) for f in os.listdir(target_dir) if f.endswith('.png') and not f.startswith('.')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DOS2Av_SMKp4"
   },
   "source": [
    "### **Tensorflow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sSppJ0YD366X"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras import layers\n",
    "import os\n",
    "import random\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JkSPhHvw5L57"
   },
   "outputs": [],
   "source": [
    "class OxfordPets(keras.utils.Sequence):\n",
    "    def __init__(self, batch_size, img_size, img_paths, label_paths):\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.img_paths = img_paths\n",
    "        self.label_paths = label_paths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label_paths)//self.batch_size\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        i = idx * self.batch_size\n",
    "        batch_img_paths = self.img_paths[i:i+self.batch_size]\n",
    "        batch_label_paths = self.label_paths[i:i+self.batch_size]\n",
    "        x = np.zeros((self.batch_size,)+self.img_size+(3,), dtype=\"float32\")\n",
    "        for j, path in enumerate(batch_img_paths):\n",
    "            img = load_img(path, target_size=self.img_size)\n",
    "            x[j] = img\n",
    "        y = np.zeros((self.batch_size,)+self.img_size+(1,), dtype=\"uint8\")\n",
    "        for j, path in enumerate(batch_label_paths):\n",
    "            img = load_img(path, target_size=self.img_size, color_mode=\"grayscale\")\n",
    "            y[j] = np.expand_dims(img, 2)\n",
    "            y[j] -= 1\t\t# 부류 번호를 1,2,3에서 0,1,2로 변환\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H5ZGbpqTNYnw"
   },
   "outputs": [],
   "source": [
    "def make_model(img_size, num_classes):\n",
    "    inputs = keras.Input(shape=img_size+(3,))\n",
    "\n",
    "    # U-net의 다운 샘플링(축소 경로)\n",
    "    x = layers.Conv2D(32, 3, strides=2, padding='same')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    previous_block_activation = x\t\t# 지름길 연결을 위해\n",
    "\n",
    "    for filters in [64,128,256]:\n",
    "        x = layers.Activation('relu')(x)\n",
    "        x = layers.SeparableConv2D(filters, 3, padding='same')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Activation('relu')(x)\n",
    "        x = layers.SeparableConv2D(filters, 3, padding='same')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.MaxPooling2D(3, strides=2, padding='same')(x)\n",
    "        residual = layers.Conv2D(filters, 1, strides=2, padding='same')(previous_block_activation)\n",
    "        x = layers.add([x, residual])\t# 지름길 연결\n",
    "        previous_block_activation = x\t# 지름길 연결을 위해\n",
    "\n",
    "    # U-net의 업 샘플링(확대 경로)\n",
    "    for filters in [256, 128, 64, 32]:\n",
    "        x = layers.Activation('relu')(x)\n",
    "        x = layers.Conv2DTranspose(filters, 3, padding='same')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Activation('relu')(x)\n",
    "        x = layers.Conv2DTranspose(filters, 3, padding='same')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.UpSampling2D(2)(x)\n",
    "        residual = layers.UpSampling2D(2)(previous_block_activation)\n",
    "        residual = layers.Conv2D(filters, 1, padding='same')(residual)\n",
    "        x = layers.add([x, residual])\t# 지름길 연결\n",
    "        previous_block_activation = x\t# 지름길 연결을 위해\n",
    "\n",
    "    outputs = layers.Conv2D(num_classes, 3, activation='softmax', padding='same')(x)\n",
    "    model = keras.Model(inputs, outputs)\t# 모델 생성\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xNR3zPVzQPx6"
   },
   "outputs": [],
   "source": [
    "model = make_model(img_siz, n_class)\t\t# 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mSnPF95KXVw4"
   },
   "outputs": [],
   "source": [
    "random.Random(1).shuffle(img_paths)\n",
    "random.Random(1).shuffle(label_paths)\n",
    "test_samples = int(len(img_paths)*0.1)\t# 10%를 테스트 집합으로 사용\n",
    "train_img_paths = img_paths[:-test_samples]\n",
    "train_label_paths = label_paths[:-test_samples]\n",
    "test_img_paths = img_paths[-test_samples:]\n",
    "test_label_paths = label_paths[-test_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DKR55SktYqHo"
   },
   "outputs": [],
   "source": [
    "train_gen = OxfordPets(batch_siz, img_siz, train_img_paths, train_label_paths) # 훈련 집합\n",
    "test_gen = OxfordPets(batch_siz, img_siz, test_img_paths, test_label_paths) # 검증 집합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oMXbyEVaZdig"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "cb = [keras.callbacks.ModelCheckpoint('oxford_seg.h5', save_best_only=True)] # 학습 결과 자동 저장\n",
    "model.fit(train_gen, epochs=30, validation_data=test_gen, callbacks=cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mq2E6-w2cFYe"
   },
   "source": [
    "### **Pytorch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EbWNoWnocHv_"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2 as cv\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OYTRyrV6_sG-"
   },
   "outputs": [],
   "source": [
    "class OxfordPets2(Dataset):\n",
    "    def __init__(self, img_size, img_paths, label_paths):\n",
    "        super().__init__()\n",
    "        self.img_size = img_size\n",
    "        self.img_paths = img_paths\n",
    "        self.label_paths = label_paths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = np.array(Image.open(self.img_paths[idx]).resize(self.img_size)) / 255.0\n",
    "        label = np.array(Image.open(self.label_paths[idx]).resize(self.img_size)) - 1\n",
    "        X = torch.FloatTensor(img).permute(2,0,1)\n",
    "        y = torch.LongTensor(label)\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q8ruqNnFcQ-Q"
   },
   "outputs": [],
   "source": [
    "class Unet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.downsample = nn.ModuleList([])\n",
    "        self.downsample_res = nn.ModuleList([])\n",
    "        self.upsample = nn.ModuleList([])\n",
    "        self.upsample_res = nn.ModuleList([])\n",
    "\n",
    "        self.downsample.append(nn.Sequential(nn.Conv2d(3, 32, 3, stride=2, padding=1), nn.BatchNorm2d(32), nn.ReLU()))\n",
    "        for filters in [64, 128, 256]:\n",
    "            self.downsample.append(self.downsamlple_block(filters))\n",
    "            self.downsample_res.append(nn.Sequential(nn.Conv2d(filters//2, filters, 3, stride=2, padding=1)))\n",
    "\n",
    "        for filters in [256, 128, 64, 32]:\n",
    "            self.upsample.append(self.upsample_block(filters))\n",
    "            self.upsample_res.append(nn.Sequential(nn.Upsample(scale_factor=2), nn.Conv2d(filters if filters==256 else filters*2, filters, 1)))\n",
    "        self.upsample.append(nn.Sequential(nn.Conv2d(32, 3, 3, padding=1)))\n",
    "\n",
    "    def downsamlple_block(self, filters):\n",
    "        modules = [nn.ReLU(),\n",
    "                   nn.Conv2d(filters//2, filters, 3, padding=1),\n",
    "                   nn.BatchNorm2d(filters),\n",
    "                   nn.ReLU(),\n",
    "                   nn.Conv2d(filters, filters, 3, padding=1),\n",
    "                   nn.BatchNorm2d(filters),\n",
    "                   nn.MaxPool2d(3, stride=2, padding=1)]\n",
    "        return nn.Sequential(*modules)\n",
    "\n",
    "    def upsample_block(self, filters):\n",
    "        modules = [nn.ReLU(),\n",
    "                   nn.ConvTranspose2d(filters if filters==256 else filters*2, filters, 3, padding=1),\n",
    "                   nn.BatchNorm2d(filters),\n",
    "                   nn.ReLU(),\n",
    "                   nn.ConvTranspose2d(filters, filters, 3, padding=1),\n",
    "                   nn.BatchNorm2d(filters),\n",
    "                   nn.Upsample(scale_factor=2)]\n",
    "        return nn.Sequential(*modules)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.downsample[0](x)\n",
    "        for i in range(len(self.downsample_res)):\n",
    "            identity = x\n",
    "            identity = self.downsample_res[i](identity)\n",
    "            x = self.downsample[i+1](x)\n",
    "            x += identity\n",
    "        for i in range(len(self.upsample_res)):\n",
    "            identity = x\n",
    "            identity = self.upsample_res[i](identity)\n",
    "            x = self.upsample[i](x)\n",
    "            x += identity\n",
    "        x = self.upsample[-1](x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4TcU3iRr6Aeh"
   },
   "outputs": [],
   "source": [
    "unet = Unet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YBKv48V6EFy9"
   },
   "outputs": [],
   "source": [
    "random.Random(1).shuffle(img_paths)\n",
    "random.Random(1).shuffle(label_paths)\n",
    "\n",
    "len_train = int(len(img_paths)*0.9)\n",
    "train_img_paths = img_paths[:len_train]\n",
    "train_label_paths = label_paths[:len_train]\n",
    "test_img_paths = img_paths[len_train:]\n",
    "test_label_paths = label_paths[len_train:]\n",
    "\n",
    "oxford_train = OxfordPets2(img_siz, train_img_paths, train_label_paths)\n",
    "oxford_test = OxfordPets2(img_siz, test_img_paths, test_label_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mCzCWrTvDLrH"
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset=oxford_train, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(dataset=oxford_test, batch_size=32, shuffle=False)\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(unet.parameters(), lr=0.001)\n",
    "epochs = 50\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    for X, y in train_dataloader:\n",
    "\n",
    "        unet.train()\n",
    "        y_pred = unet(X)\n",
    "        train_loss = loss(y_pred, y)\n",
    "        print(train_loss.item())  # loss 줄어들고 있는지 확인\n",
    "\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
