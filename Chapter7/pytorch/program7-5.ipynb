{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245716c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as ds\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e953827",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = ds.MNIST(root=\".\", train=True, transform=transforms.ToTensor(), download=True)\n",
    "mnist_test = ds.MNIST(root=\".\", train=False, transform=transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da56ccbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.hid1 = nn.Sequential(nn.Linear(784,1024), nn.ReLU())\n",
    "        self.hid2 = nn.Sequential(nn.Linear(1024,512), nn.ReLU())\n",
    "        self.hid3 = nn.Sequential(nn.Linear(512,512), nn.ReLU())\n",
    "        self.out = nn.Linear(512,10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.hid1(x)\n",
    "        x = self.hid2(x)\n",
    "        x = self.hid3(x)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n",
    "dmlp = MLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a111f96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset=mnist_train, batch_size=128, shuffle=True) \n",
    "test_dataloader = DataLoader(dataset=mnist_test, batch_size=128, shuffle=True)\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(dmlp.parameters(), lr=0.0001)\n",
    "epochs = 50\n",
    "train_acc_dmlp, test_acc_dmlp = [], []\n",
    "train_loss_dmlp, test_loss_dmlp = [], []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    train_loss_iter, test_loss_iter = [], []\n",
    "    train_acc_iter, test_acc_iter = [], []\n",
    "    \n",
    "    for X, y in train_dataloader:\n",
    "    \n",
    "        dmlp.train()\n",
    "        y_pred = dmlp(X)\n",
    "        train_loss = loss(y_pred, y)\n",
    "        train_loss_iter.append(train_loss.item())\n",
    "        train_acc = (torch.argmax(y_pred, axis=1) == y).sum() / len(y)\n",
    "        train_acc_iter.append(train_acc.item())\n",
    "\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    for X, y in test_dataloader:\n",
    "    \n",
    "        dmlp.eval()\n",
    "        with torch.no_grad():\n",
    "            y_pred = dmlp(X)\n",
    "            test_loss = loss(y_pred, y)\n",
    "            test_loss_iter.append(test_loss.item())\n",
    "            test_acc = (torch.argmax(y_pred, axis=1) == y).sum() / len(y)\n",
    "            test_acc_iter.append(test_acc.item())\n",
    "            \n",
    "    train_loss_epoch = round(np.array(train_loss_iter).mean(), 4)\n",
    "    train_acc_epoch = round(np.array(train_acc_iter).mean(), 4)\n",
    "    test_loss_epoch = round(np.array(test_loss_iter).mean(), 4)\n",
    "    test_acc_epoch = round(np.array(test_acc_iter).mean(), 4)\n",
    "    \n",
    "    train_loss_dmlp.append(train_loss_epoch)\n",
    "    train_acc_dmlp.append(train_acc_epoch)\n",
    "    test_loss_dmlp.append(test_loss_epoch)\n",
    "    test_acc_dmlp.append(test_acc_epoch)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{epochs}\\tloss: {train_loss_epoch}\\taccuracy: {train_acc_epoch} \\\n",
    "    val loss: {test_loss_epoch}\\tval accuracy: {test_acc_epoch}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28600187",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc_list = []\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    \n",
    "    dmlp.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = dmlp(X)\n",
    "        test_acc = (torch.argmax(y_pred, axis=1) == y).sum() / len(y)\n",
    "        test_acc_list.append(test_acc.item())\n",
    "\n",
    "res = np.array(test_acc_list).mean()\n",
    "print(f\"정확률 = {res*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467a4c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(dmlp.state_dict(), \"dmlp_trained.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea0b7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0115e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_acc_dmlp)\n",
    "plt.plot(test_acc_dmlp)\n",
    "plt.title(\"Accuracy graph\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.legend([\"train\", \"test\"])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46361a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss_dmlp)\n",
    "plt.plot(test_loss_dmlp)\n",
    "plt.title(\"Loss graph\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend([\"train\", \"test\"])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
